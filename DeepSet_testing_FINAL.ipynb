{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Copy of GNN final project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81f921fcc2254511869d1c383485d922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a86d934842b640ea8d523d0cb10d6b1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31fe222b7b4d43ba9d614520418a2f5c",
              "IPY_MODEL_7fe51f8014c34ffbb22bfbe167570c17"
            ]
          }
        },
        "a86d934842b640ea8d523d0cb10d6b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31fe222b7b4d43ba9d614520418a2f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42e16d3accca4bb599dc5191291349e9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 8958,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8958,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_542db7bd63984fc5a4a3670fbc103952"
          }
        },
        "7fe51f8014c34ffbb22bfbe167570c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_403f347ae05d4eacb136bf21314e0c37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8958/8958 [01:22&lt;00:00, 108.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58a913dadea14068b904a24b54f0a01f"
          }
        },
        "42e16d3accca4bb599dc5191291349e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "542db7bd63984fc5a4a3670fbc103952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "403f347ae05d4eacb136bf21314e0c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58a913dadea14068b904a24b54f0a01f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erezimm/ML-ML/blob/master/DeepSet_testing_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCU4DoTLIIoO",
        "colab_type": "text"
      },
      "source": [
        "# Main notebook, to be run on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWYU8-BTJ-XN",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies and download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5E9Y_nnn3m8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "1475ee5f-3cf4-47ea-8bf1-b1e753c1772b"
      },
      "source": [
        "!pip install dgl\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "import astropy.io.ascii\n",
        "import dgl\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise Exception('Cuda unavailable, turn it on under Runtime>Change runtime type>GPU')\n",
        "device = torch.device('cuda')\n",
        "\n",
        "\n",
        "\n",
        "!wget -O data.zip https://www.dropbox.com/s/kp0o01qirqw8pef/data_r_false.zip?dl=1\n",
        "!unzip -o -q data.zip -d /content/\n",
        "\n",
        "\n",
        "validation_path = '/content/data_r_false'\n",
        "\n",
        "# microlist = glob.glob(data_path+'/microlensedconst_*')\n",
        "# varlist = glob.glob(data_path+'/cleanvar_*')\n",
        "# for typelist in (microlist, varlist):\n",
        "#     for i, f in enumerate(typelist):\n",
        "#         dest = training_path if i<len(microlist)/2 else validation_path\n",
        "#         shutil.move(f, os.path.join(dest, os.path.basename(f)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "  Using cached https://files.pythonhosted.org/packages/c5/b4/84e4ebd70ef3985181ef5d2d2a366a45af0e3cd18d249fb212ac03f683cf/dgl-0.4.3.post2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.18.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.3.post2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "--2020-08-19 11:22:22--  https://www.dropbox.com/s/kp0o01qirqw8pef/data_r_false.zip?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/kp0o01qirqw8pef/data_r_false.zip [following]\n",
            "--2020-08-19 11:22:22--  https://www.dropbox.com/s/dl/kp0o01qirqw8pef/data_r_false.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc844f40ece52ab8cdfc88de756b.dl.dropboxusercontent.com/cd/0/get/A9sbmJSX_y9_QpYVjE_-5FsgwBjhXFD5LRnMrKRwuGKWCfCCrVcxjTzPviu97RQWjhrML5raP0cI76vMxxcfkdYaWi0EcaJWgHqJedJwYxuydKCtkQnNgEL5V1L2goe8yRA/file?dl=1# [following]\n",
            "--2020-08-19 11:22:22--  https://uc844f40ece52ab8cdfc88de756b.dl.dropboxusercontent.com/cd/0/get/A9sbmJSX_y9_QpYVjE_-5FsgwBjhXFD5LRnMrKRwuGKWCfCCrVcxjTzPviu97RQWjhrML5raP0cI76vMxxcfkdYaWi0EcaJWgHqJedJwYxuydKCtkQnNgEL5V1L2goe8yRA/file?dl=1\n",
            "Resolving uc844f40ece52ab8cdfc88de756b.dl.dropboxusercontent.com (uc844f40ece52ab8cdfc88de756b.dl.dropboxusercontent.com)... 162.125.82.15, 2620:100:6032:15::a27d:520f\n",
            "Connecting to uc844f40ece52ab8cdfc88de756b.dl.dropboxusercontent.com (uc844f40ece52ab8cdfc88de756b.dl.dropboxusercontent.com)|162.125.82.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5518714 (5.3M) [application/binary]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   5.26M  19.5MB/s    in 0.3s    \n",
            "\n",
            "2020-08-19 11:22:23 (19.5 MB/s) - ‘data.zip’ saved [5518714/5518714]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZoh9gELfIPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [10,10]  # hidden layers in the DeepSetLayer\n",
        "outputsize = 7  # length of the representation passed to the final network\n",
        "cllayers = [10,5,5]  # hidden layers in the final network (takes outputsize, returns a scalar which is the classification)\n",
        "\n",
        "def build_layers(inp,out,sizes):\n",
        "    sizes = [inp]+sizes+[out]\n",
        "    layers = []\n",
        "    for i in range(len(sizes)-1):\n",
        "        layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.LeakyReLU()])\n",
        "    \n",
        "    return layers\n",
        "\n",
        "\n",
        "# #Deep Set\n",
        "\n",
        "class DeepSet(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(DeepSet, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        self.layers.append(DeepSetLayer(config['inputsize'], config['layers'][0], config['inputs'], config['output'] ))\n",
        "\n",
        "        n_layers = len(config['layers'])\n",
        "\n",
        "        for i in range(n_layers - 1):\n",
        "\n",
        "            self.layers.append(DeepSetLayer(config['inputsize']+ config['layers'][i],\n",
        "                                            config['layers'][i+1], \n",
        "                                            config['inputs'] + [config['output']], \n",
        "                                            config['output']))\n",
        "            \n",
        "\n",
        "        self.layers.append(DeepSetLayer(config['inputsize']+ config['layers'][-1],\n",
        "                                            config['outputsize'], \n",
        "                                            config['inputs'] + [config['output']],\n",
        "                                            config['output']))  \n",
        "\n",
        "        layers = build_layers(config['outputsize'], 2, config['cllayers'])  # OFEK chnaged to output=2\n",
        "        self.classifier = nn.Sequential(*(layers+ [nn.Softmax()]))  # OFEK added SoftMax\n",
        "    \n",
        "    def forward(self, g):\n",
        "\n",
        "        for layer in self.layers:\n",
        "            \n",
        "            g = layer(g) \n",
        "\n",
        "        mean_nodes= dgl.mean_nodes(g, 'node_embed', weight = None)\n",
        "        output = self.classifier(mean_nodes)\n",
        "\n",
        "\n",
        "        return output \n",
        "class DeepSetLayer(nn.Module):\n",
        "    def __init__(self, inputsize, outputsize, inputnames, outputname):\n",
        "        \n",
        "\n",
        "\n",
        "        super(DeepSetLayer,self).__init__()\n",
        "\n",
        "        self.inputs      = inputnames\n",
        "        self.outputname = outputname\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "        layers = build_layers(inputsize, outputsize, [int(0.5*(outputsize + inputsize)   )])\n",
        "\n",
        "        self.node_embedd = nn.Sequential(*layers)\n",
        "\n",
        "        layers = build_layers(outputsize + inputsize, outputsize,[ int( 0.5*(outputsize + inputsize)) ] )\n",
        "\n",
        "        self.node_update = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, g):\n",
        "\n",
        "        gn = [g.ndata[inputname] for inputname in self.inputs]\n",
        "        unsqdim = max(max([len(n.shape) for n in gn]),2)\n",
        "        tocat = []\n",
        "        for n in gn:\n",
        "            t = n\n",
        "            for _ in range(unsqdim-len(n.shape)):\n",
        "                t = t.unsqueeze(-1)\n",
        "            tocat.append(t)\n",
        "            # print(t.shape)\n",
        "        node_data = torch.cat(tocat, dim=1)\n",
        "\n",
        "        g.ndata['node_embed'] = self.node_embedd(node_data)\n",
        "\n",
        "\n",
        "        node_sum = dgl.mean_nodes(g, 'node_embed', weight = None)  #Global representation of graph \n",
        "\n",
        "        g.ndata['mean_nodes'] = dgl.broadcast_nodes(g, node_sum)\n",
        "        \n",
        "        \n",
        "\n",
        "        gn = [g.ndata[inputname] for inputname in self.inputs] + [g.ndata['mean_nodes']]\n",
        "        unsqdim = max(max([len(n.shape) for n in gn]),2)\n",
        "        tocat = []\n",
        "        for n in gn:\n",
        "            t = n\n",
        "            for _ in range(unsqdim-len(n.shape)):\n",
        "                t = t.unsqueeze(-1)\n",
        "            tocat.append(t)\n",
        "            # print(t.shape)\n",
        "        node_update_input = torch.cat( tocat, dim=1  )\n",
        "\n",
        "        g.ndata[self.outputname] = self.node_update(node_update_input)\n",
        "\n",
        "\n",
        "        return g #contains global information \n",
        "\n",
        "\n",
        "net = DeepSet({'inputsize':3 , 'outputsize':outputsize, 'inputs':['time', 'mag', 'magerr'], 'output':'finalrep', 'layers':layers, 'cllayers':cllayers})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ3GgfWQdsmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d0964dc6-990a-41c2-86f3-9618c7c583f6"
      },
      "source": [
        "!wget -O model.pt https://github.com/erezimm/ML-ML/raw/master/models/training-red-8k8k_PDPFA-96-11_realacc-r74-g84.pt\n",
        "net.load_state_dict(torch.load('model.pt'))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-19 11:32:10--  https://github.com/erezimm/ML-ML/raw/master/models/training-red-8k8k_PDPFA-96-11_realacc-r74-g84.pt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/erezimm/ML-ML/master/models/training-red-8k8k_PDPFA-96-11_realacc-r74-g84.pt [following]\n",
            "--2020-08-19 11:32:11--  https://raw.githubusercontent.com/erezimm/ML-ML/master/models/training-red-8k8k_PDPFA-96-11_realacc-r74-g84.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17229 (17K) [application/octet-stream]\n",
            "Saving to: ‘model.pt’\n",
            "\n",
            "model.pt            100%[===================>]  16.83K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-08-19 11:32:11 (1.38 MB/s) - ‘model.pt’ saved [17229/17229]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff2ASGtVn3nB",
        "colab_type": "text"
      },
      "source": [
        "## Create Datasets\n",
        "Class CustomDataset loads all files and converts them to a list of graphs.\n",
        "Each node in a graph is a data point, i.e. node features are days since start, mag, magerr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSLI4uNYn3nB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "81f921fcc2254511869d1c383485d922",
            "a86d934842b640ea8d523d0cb10d6b1f",
            "31fe222b7b4d43ba9d614520418a2f5c",
            "7fe51f8014c34ffbb22bfbe167570c17",
            "42e16d3accca4bb599dc5191291349e9",
            "542db7bd63984fc5a4a3670fbc103952",
            "403f347ae05d4eacb136bf21314e0c37",
            "58a913dadea14068b904a24b54f0a01f"
          ]
        },
        "outputId": "ba211879-d81c-4423-f1dc-56efd0eb6674"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        filelist = glob.glob(path+'/*')\n",
        "        \n",
        "        self.graphs = []\n",
        "        self.isMicrolensed = []\n",
        "        for fname in tqdm(filelist):\n",
        "            filebasename = os.path.basename(fname)\n",
        "            if filebasename.startswith('cleanvar'):\n",
        "                microlensed = torch.tensor([0])\n",
        "            elif filebasename.startswith('microlensedconst'):\n",
        "                microlensed = torch.tensor([1])\n",
        "            else:\n",
        "                raise Exception('Filename ' + fname + ' not clean_* or microlensed_*')\n",
        "            \n",
        "            with open(fname) as f:\n",
        "                data = astropy.io.ascii.read(f.read())\n",
        "                times, mags, magerrs = data['col1'], [], data['col3']\n",
        "                for m, err in zip(data['col2'], magerrs):\n",
        "                    mags.append(round(m, len(str(err).split('.')[1])))\n",
        "                zipped = list(zip(times, mags, magerrs))\n",
        "                zipped.sort(key=lambda tup: tup[0])\n",
        "                times, mags, magerrs = zip(*zipped)\n",
        "                times, mags, magerrs =torch.tensor(times), torch.tensor(mags), torch.tensor(magerrs)\n",
        "                \n",
        "                times = times - min(times)\n",
        "                flux = 10 ** (mags/(-2.5))\n",
        "                medflux = torch.median(flux)\n",
        "                flux = flux/medflux\n",
        "                fluxerr = flux * magerrs * np.log(10) * 0.4 / medflux\n",
        "\n",
        "                n = len(times)\n",
        "                g = dgl.DGLGraph()\n",
        "                g.add_nodes(n)\n",
        "                g.ndata['time'] = torch.tensor(times).float()  # days\n",
        "                g.ndata['mag'] = torch.tensor(flux).float()\n",
        "                g.ndata['magerr'] = torch.tensor(fluxerr).float()\n",
        "\n",
        "\n",
        "                #g.add_edges([i for i in range(n)], [(i+1)%n for i in range(n)])\n",
        "                #g.add_edges([i for i in range(n)], [(i-1)%n for i in range(n)])\n",
        "                \n",
        "                self.graphs.append(g)\n",
        "                self.isMicrolensed.append(microlensed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx], self.isMicrolensed[idx]\n",
        "\n",
        "def collate(samples):\n",
        "    # The input `samples` is a list, a batch of whatever comes out of your dataset object\n",
        "    graphs = [x[0] for x in samples]\n",
        "    labels = [x[1] for x in samples]\n",
        "    \n",
        "    batched_graph = dgl.batch(graphs, node_attrs=['time', 'mag', 'magerr'])\n",
        "    targets = torch.cat(labels)\n",
        "    \n",
        "    return batched_graph, targets.unsqueeze(1).float()\n",
        "\n",
        "\n",
        "validation_ds = CustomDataset(validation_path)\n",
        "\n",
        "nx.draw(dgl.to_networkx(validation_ds[20][0]))\n",
        "\n",
        "print('valid set size:', len(validation_ds))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81f921fcc2254511869d1c383485d922",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=8958.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "valid set size: 8958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGDTIcKIuGW2",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgrXh0Jdn3nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(net, validation_ds):\n",
        "    test_data_loader = DataLoader(validation_ds, batch_size=1000, shuffle=True, collate_fn=collate)\n",
        "\n",
        "    net.cpu()\n",
        "    net.eval()\n",
        "\n",
        "    true_positive = 0\n",
        "    false_positive = 0\n",
        "    true_negative = 0\n",
        "    false_negative = 0\n",
        "    total_positives = 0\n",
        "    total_negatives = 0\n",
        "\n",
        "    for i, (x,y) in enumerate(test_data_loader):\n",
        "            y = y.data.numpy()\n",
        "            y = y.transpose()\n",
        "            prediction = net(x).cpu().data.numpy()\n",
        "            pred = (prediction[:,1]>prediction[:,0])\n",
        "            \n",
        "            total_positives+=len(np.where( y==1 )[0])\n",
        "            total_negatives+=len(np.where( y==0 )[0])\n",
        "            \n",
        "\n",
        "            true_positive+= len(np.where( (pred==1) & (y==1) )[0])\n",
        "            false_positive+= len(np.where( (pred==1) & (y==0) )[0])\n",
        "    # print(pred, prediction, y)\n",
        "    if total_positives>0:\n",
        "        print('Probability of detection:', true_positive/total_positives)  # probability of recognizing a microlensing when you see it\n",
        "    if total_negatives>0:\n",
        "        print('Probability of false alarm:', false_positive/total_negatives)  # probability for misclassification of a variable star as microlensing"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzJjaN2HdjOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "caf76520-64ac-4ec6-ff56-c92791e5b52b"
      },
      "source": [
        "evaluate(net, validation_ds)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Probability of false alarm: 0.10593882563072114\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}