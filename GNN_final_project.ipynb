{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "GNN final project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erezimm/ML-ML/blob/master/GNN_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCU4DoTLIIoO",
        "colab_type": "text"
      },
      "source": [
        "# Main notebook, to be run on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWYU8-BTJ-XN",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies and download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5E9Y_nnn3m8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "7002b4ed-18e0-478c-c226-cac77c91aaaa"
      },
      "source": [
        "!pip install dgl\n",
        "\n",
        "from datetime import date\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl import DGLGraph\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import astropy.io.ascii\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!wget -O data.zip https://github.com/erezimm/ML-ML/raw/master/data.zip\n",
        "!unzip -o -q data.zip -d ./data\n",
        "training_path = '/content/data/training_set'\n",
        "validation_path = '/content/data/validation_set'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "  Using cached https://files.pythonhosted.org/packages/c5/b4/84e4ebd70ef3985181ef5d2d2a366a45af0e3cd18d249fb212ac03f683cf/dgl-0.4.3.post2-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.3.post2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "--2020-08-05 11:38:22--  https://github.com/erezimm/ML-ML/raw/master/data.zip\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/erezimm/ML-ML/master/data.zip [following]\n",
            "--2020-08-05 11:38:22--  https://raw.githubusercontent.com/erezimm/ML-ML/master/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59777 (58K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  58.38K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2020-08-05 11:38:22 (7.53 MB/s) - ‘data.zip’ saved [59777/59777]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff2ASGtVn3nB",
        "colab_type": "text"
      },
      "source": [
        "## Class CustomDataset loads all files and converts them to a list of graphs\n",
        "\n",
        "Each node in a graph is a data point, i.e. node features are days since start, mag, magerr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSLI4uNYn3nB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ebd69835-1392-4f38-9c7b-16c48484d457"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        filelist = glob.glob(path+'/*')\n",
        "        \n",
        "        self.graphs = []\n",
        "        self.isMicrolensed = []\n",
        "        for fname in tqdm(filelist):\n",
        "            if fname.startswith('clean')\n",
        "                microlensed = False\n",
        "            elif fname.startswith('microlensed'):\n",
        "                microlensed = True\n",
        "            else:\n",
        "                raise Exception('Filename ' + fname + ' not clean_*/microlensed_*')\n",
        "            \n",
        "            with open(fname) as f:\n",
        "                data = astropy.io.ascii.read(f.read())\n",
        "                times, mags, magerrs = data['col1'], data['col2'], data['col3']\n",
        "                zipped = list(zip(times, mags, magerrs))\n",
        "                zipped.sort(key=lambda tup: tup[0])\n",
        "                times, mags, magerrs = zip(*zipped)\n",
        "\n",
        "                n = len(times)\n",
        "                g = dgl.DGLGraph()\n",
        "                g.add_nodes(n)\n",
        "                g.ndata['time'] = torch.tensor(times)  # days\n",
        "                g.ndata['mag'] = torch.tensor(mags)\n",
        "                g.ndata['magerr'] = torch.tensor(magerrs)\n",
        "                g.add_edges([i for i in range(n)], [(i+1)%n for i in range(n)])\n",
        "                g.add_edges([i for i in range(n)], [(i-1)%n for i in range(n)])\n",
        "                \n",
        "                self.graphs.append(g)\n",
        "                self.isMicrolensed.append(microlensed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx], self.isMicrolensed[idx]\n",
        "\n",
        "\n",
        "train_ds = CustomDataset(training_path)\n",
        "# validation_ds = CustomDataset(validation_path)\n",
        "\n",
        "nx.draw(dgl.to_networkx(train_ds[20][0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-7bdbd1f2bb10>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    if fname.startswith('clean')\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnD7mWfjn3nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(samples):\n",
        "    # The input `samples` is a list, a batch of whatever comes out of your dataset object\n",
        "    graphs = [x[0] for x in samples]\n",
        "    labels = [x[1] for x in samples]\n",
        "    \n",
        "    batched_graph = dgl.batch(graphs,node_attrs=['time', 'mag', 'magerr'])\n",
        "    targets = torch.cat(labels)\n",
        "    \n",
        "    return batched_graph, targets.unsqueeze(1).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGDTIcKIuGW2",
        "colab_type": "text"
      },
      "source": [
        "## The Newtwork"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs14d7QUn3nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_ft = 3  # number of node features (time, mag, magerr)\n",
        "\n",
        "class EdgeNetwork(nn.Module):\n",
        "    def __init__(self, node_hidrep, edge_hidrep):\n",
        "        super(EdgeNetwork, self).__init__()\n",
        "        n_in = 2*(n_ft + node_hidrep) + edge_hidrep\n",
        "        \n",
        "        # params:\n",
        "        sizes = [n_in] + [] + [edge_hidrep]  # edit middle list, can be empty\n",
        "\n",
        "        # create networks:\n",
        "        layers = []\n",
        "        for i in range(len(sizes)-1):\n",
        "            layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.ReLU()])\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #your input x is an object with the following properties:\n",
        "        # x.dst['node_features'], x.dst['node_hidden_state']\n",
        "        # x.src['node_features'], x.src['node_hidden_state']\n",
        "        # x.data['distance']\n",
        "        \n",
        "        #put them together with torch.cat\n",
        "\n",
        "        # print( x.dst['node_features'].shape, x.dst['node_hidden_state'].shape,\n",
        "        #                     x.src['node_features'].shape, x.src['node_hidden_state'].shape,\n",
        "        #                     x.data['distance'].shape)\n",
        "\n",
        "        input = torch.cat(( x.dst['time'], x.dst['mag'], x.dst['magerr'], x.dst['node_hidrep'],\n",
        "                            x.src['time'], x.src['mag'], x.src['magerr'], x.src['node_hidrep'],\n",
        "                            x.data['edge_hidrep'] ), dim=1)\n",
        "        \n",
        "        #use a neural network to create an edge hidden represetation - \n",
        "\n",
        "        output = self.network(input)\n",
        "\n",
        "        #you return a dictionary with what you want to \"send\" to the reciving node\n",
        "        return {'edge_hidrep': output }\n",
        "\n",
        "    \n",
        "class NodeNetwork(nn.Module):\n",
        "    def __init__(self, node_hidrep, edge_hidrep):\n",
        "        super(NodeNetwork, self).__init__()\n",
        "        n_in = 2*edge_hidrep + node_hidrep + n_ft\n",
        "\n",
        "        # params:\n",
        "        sizes = [n_in] + [] + [node_hidrep]  # edit middle list, can be empty\n",
        "\n",
        "        # create networks:\n",
        "        layers = []\n",
        "        for i in range(len(sizes)-1):\n",
        "            layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.ReLU()])\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #this time your input x has:\n",
        "        # x.mailbox['edge hidden represetation'] -> this is what you send with the edge update function above - \n",
        "        # it will have the size of the node neighborhood - \n",
        "        # (Batch size, number of nodes in neighborhood, edge hidden rep size), so you need to sum/mean over dim=1 \n",
        "        # x.data['node_hidden_state'] and x.data['node_features'] (this is the existing state of your node)\n",
        "        # you need to torch.cat the message sum, node hidden state, and node features \n",
        "        #- and then apply some fully connected neural network\n",
        "        \n",
        "        input = torch.mean( x.mailbox['edge_hidrep'] , dim=1 )\n",
        "\n",
        "        # print( mb.shape, x.data['node_hidden_state'].shape, x.data['node_features'].shape )\n",
        "\n",
        "        input = torch.cat((mb, x.data['node_hidrep'], x.data['time'], x.data['mag'], x.data['magerr']), dim=1)\n",
        "        out = self.network(input)\n",
        "\n",
        "        # return a new hidden state for the node\n",
        "        return {'node_hidrep': out }\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        # params:\n",
        "        node_hidrep, edge_hidrep = 10, 10\n",
        "        sizes_nodeinit = [n_ft] + [] + [node_hidrep]  # edit middle list, can be empty\n",
        "        self.update_loop_length = 20\n",
        "\n",
        "        # create networks:\n",
        "        layers = []\n",
        "        for i in range(len(sizes_nodeinit)-1):\n",
        "            layers.extend([nn.Linear(sizes_nodeinit[i], sizes_nodeinit[i+1]), nn.ReLU()])\n",
        "        self.node_init = nn.Sequential(*layers)\n",
        "        self.edge_network = EdgeNetwork(node_hidrep, edge_hidrep)\n",
        "        self.node_network = NodeNetwork(node_hidrep, edge_hidrep)\n",
        "        \n",
        "    def forward(self, g):\n",
        "        g.ndata['node_hidrep'] = self.node_init(torch.cat((g.ndata['time'], g.ndata['mag'], g.ndata['magerr'])))\n",
        "        for i in range(self.update_loop_length):\n",
        "            g.update_all(self.edge_network, self.node_network)\n",
        "        \n",
        "        out = 0\n",
        "        for x in g.ndata['node_hidrep']:\n",
        "            out = max(out, torch.sum(x))\n",
        "        return out "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWotzRtQn3nT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('Cuda on')\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "  print('No Cuda')\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "net = Classifier()\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x-ALDRlwBDo",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvADGO3ZvS9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "E0-E3v84n3nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = DataLoader(train_ds, batch_size=30, shuffle=True, collate_fn=collate)\n",
        "\n",
        "n_epochs = 50\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    net.train()\n",
        "    losses = []\n",
        "    for x,y in data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(x)\n",
        "        # print(output.shape, y.shape)\n",
        "        loss = loss_func(output,y)\n",
        "        losses.append(float(loss))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    print(epoch, ':', np.mean(np.array(losses)))      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUcd0CE9wIXq",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate\n",
        "\n",
        "Once you train your network you can evaluate on the test dataset, and compute the rate of false positive, false negative, etc,\n",
        "\n",
        "train until you reach at least 60% true positive rate while maintaining a 90%+ true negative rate, and submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgrXh0Jdn3nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_loader = DataLoader(test_ds, batch_size=30, shuffle=True, collate_fn=collate)\n",
        "\n",
        "net.cpu()\n",
        "net.eval()\n",
        "\n",
        "true_positive = 0\n",
        "false_positive = 0\n",
        "true_negative = 0\n",
        "false_negative = 0\n",
        "total_positives = 0\n",
        "total_negatives = 0\n",
        "\n",
        "for i, (x,y) in enumerate(test_data_loader):\n",
        "        \n",
        "        y = y.data.numpy()\n",
        "\n",
        "        prediction = net(x).cpu().data.numpy()\n",
        "        \n",
        "        prediction[prediction >= 0.5] = 1\n",
        "        prediction[prediction <0.5] = 0\n",
        "        \n",
        "        total_positives+=len(np.where( y==1 )[0])\n",
        "        total_negatives+=len(np.where( y==0 )[0])\n",
        "        \n",
        "        true_positive+= len(np.where( (prediction==y) & (y==1) )[0])\n",
        "        true_negative+= len(np.where( (prediction==y) & (y==0) )[0])\n",
        "        false_positive+= len(np.where( (prediction!=y) & (y==0) )[0])\n",
        "        false_negative+= len(np.where( (prediction!=y) & (y==1) )[0])\n",
        "        \n",
        "        \n",
        "print('true positive: ', true_positive/total_positives)\n",
        "print(false_negative/total_positives)\n",
        "print('true negative: ', true_negative/total_negatives)\n",
        "print(false_positive/total_negatives)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VfHxWg7aL98",
        "colab_type": "text"
      },
      "source": [
        "## Save\n",
        "Don't forget to download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cVQVmottKTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(net.state_dict(), 'ML-ML/models/model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}