{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Copy of GNN final project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08c31a535a8e41d08e4de0258465a7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5dfefecfd15746619621894a596c1ed3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_050087c93dc34e5c805b50fbb71c42a1",
              "IPY_MODEL_f439c318dcf346e39f4282e98725af82"
            ]
          }
        },
        "5dfefecfd15746619621894a596c1ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "050087c93dc34e5c805b50fbb71c42a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_093b52392d614d96b5c120505408db19",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71fb88a1ebd54db686fe9ce700b2bfdf"
          }
        },
        "f439c318dcf346e39f4282e98725af82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6eeccee2b91405f8617d3cf391d1eac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000/5000 [00:37&lt;00:00, 133.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c73335f586548aea4ffc529dd52e0bb"
          }
        },
        "093b52392d614d96b5c120505408db19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71fb88a1ebd54db686fe9ce700b2bfdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6eeccee2b91405f8617d3cf391d1eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c73335f586548aea4ffc529dd52e0bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3baaca75c8ac4027a65cb63eb154c214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a703f339b4949ac9b683c69ace7ef49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44beb493f8714e288863397b13b8dfbb",
              "IPY_MODEL_4fb11761de5147c0a84d1953daf7a1dc"
            ]
          }
        },
        "0a703f339b4949ac9b683c69ace7ef49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44beb493f8714e288863397b13b8dfbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68d14e4f23da4677898eef764f898ff3",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_653fcbc4585d46dc9447b452a0bb552e"
          }
        },
        "4fb11761de5147c0a84d1953daf7a1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4fb525a9d53b42058b4050c9f71f27ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5000/5000 [00:28&lt;00:00, 172.79it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1193310cd4447e39984b5bbce6f9df5"
          }
        },
        "68d14e4f23da4677898eef764f898ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "653fcbc4585d46dc9447b452a0bb552e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fb525a9d53b42058b4050c9f71f27ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1193310cd4447e39984b5bbce6f9df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1889ba1fdf9475797d0376e88ee2cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65ee33fc01504673b3ed56550180fb42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9376ee0ceac6464f8da1c2a33f8450de",
              "IPY_MODEL_15d8f389980f408898559480e78b19c0"
            ]
          }
        },
        "65ee33fc01504673b3ed56550180fb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9376ee0ceac6464f8da1c2a33f8450de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67f876a4f5b94b5abcebb0d801650ca0",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85b02d8e2eec4989afc85c457e64b6da"
          }
        },
        "15d8f389980f408898559480e78b19c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a36ee0d1a5d84363b2fcedd2a88d02f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/10 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_268086fc962b41c6805ada2c20dc3efa"
          }
        },
        "67f876a4f5b94b5abcebb0d801650ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85b02d8e2eec4989afc85c457e64b6da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a36ee0d1a5d84363b2fcedd2a88d02f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "268086fc962b41c6805ada2c20dc3efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erezimm/ML-ML/blob/master/GNN_final_project_sam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCU4DoTLIIoO",
        "colab_type": "text"
      },
      "source": [
        "# Main notebook, to be run on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWYU8-BTJ-XN",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies and download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5E9Y_nnn3m8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "68953fa3-458a-45a2-bbb7-9f34ef39432b"
      },
      "source": [
        "!pip install dgl\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "import astropy.io.ascii\n",
        "import dgl\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise Exception('Cuda unavailable, turn it on under Runtime>Change runtime type>GPU')\n",
        "device = torch.device('cpu')\n",
        "\n",
        "training_path = '/content/training_set'\n",
        "validation_path = '/content/validation_set'\n",
        "for path in (training_path, validation_path):\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "!wget -O data.zip https://github.com/erezimm/ML-ML/raw/master/data.zip\n",
        "!unzip -o -q data.zip -d /content/\n",
        "data_path = '/content/data'\n",
        "microlist = glob.glob(data_path+'/microlensedconst_*')\n",
        "varlist = glob.glob(data_path+'/cleanvar_*')\n",
        "for typelist in (microlist, varlist):\n",
        "    for i, f in enumerate(typelist):\n",
        "        dest = training_path if i<len(microlist)/2 else validation_path\n",
        "        shutil.move(f, os.path.join(dest, os.path.basename(f)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/b4/84e4ebd70ef3985181ef5d2d2a366a45af0e3cd18d249fb212ac03f683cf/dgl-0.4.3.post2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.4.3.post2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "--2020-08-10 06:01:31--  https://github.com/erezimm/ML-ML/raw/master/data.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/erezimm/ML-ML/master/data.zip [following]\n",
            "--2020-08-10 06:01:32--  https://raw.githubusercontent.com/erezimm/ML-ML/master/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6541642 (6.2M) [application/zip]\n",
            "Saving to: â€˜data.zipâ€™\n",
            "\n",
            "data.zip            100%[===================>]   6.24M  24.5MB/s    in 0.3s    \n",
            "\n",
            "2020-08-10 06:01:33 (24.5 MB/s) - â€˜data.zipâ€™ saved [6541642/6541642]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff2ASGtVn3nB",
        "colab_type": "text"
      },
      "source": [
        "## Create Datasets\n",
        "Class CustomDataset loads all files and converts them to a list of graphs.\n",
        "Each node in a graph is a data point, i.e. node features are days since start, mag, magerr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSLI4uNYn3nB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "08c31a535a8e41d08e4de0258465a7fd",
            "5dfefecfd15746619621894a596c1ed3",
            "050087c93dc34e5c805b50fbb71c42a1",
            "f439c318dcf346e39f4282e98725af82",
            "093b52392d614d96b5c120505408db19",
            "71fb88a1ebd54db686fe9ce700b2bfdf",
            "f6eeccee2b91405f8617d3cf391d1eac",
            "7c73335f586548aea4ffc529dd52e0bb",
            "3baaca75c8ac4027a65cb63eb154c214",
            "0a703f339b4949ac9b683c69ace7ef49",
            "44beb493f8714e288863397b13b8dfbb",
            "4fb11761de5147c0a84d1953daf7a1dc",
            "68d14e4f23da4677898eef764f898ff3",
            "653fcbc4585d46dc9447b452a0bb552e",
            "4fb525a9d53b42058b4050c9f71f27ba",
            "f1193310cd4447e39984b5bbce6f9df5"
          ]
        },
        "outputId": "dc640447-af2b-4d6e-b037-d9c086f15533"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        filelist = glob.glob(path+'/*')\n",
        "        \n",
        "        self.graphs = []\n",
        "        self.isMicrolensed = []\n",
        "        for fname in tqdm(filelist):\n",
        "            filebasename = os.path.basename(fname)\n",
        "            if filebasename.startswith('cleanvar'):\n",
        "                microlensed = torch.tensor([0])\n",
        "            elif filebasename.startswith('microlensedconst'):\n",
        "                microlensed = torch.tensor([1])\n",
        "            else:\n",
        "                raise Exception('Filename ' + fname + ' not clean_* or microlensed_*')\n",
        "            \n",
        "            with open(fname) as f:\n",
        "                data = astropy.io.ascii.read(f.read())\n",
        "                times, mags, magerrs = data['col1'], [], data['col3']\n",
        "                for m, err in zip(data['col2'], magerrs):\n",
        "                    mags.append(round(m, len(str(err).split('.')[1])))\n",
        "                zipped = list(zip(times, mags, magerrs))\n",
        "                zipped.sort(key=lambda tup: tup[0])\n",
        "                times, mags, magerrs = zip(*zipped)\n",
        "\n",
        "                n = len(times)\n",
        "                g = dgl.DGLGraph()\n",
        "                g.add_nodes(n)\n",
        "                g.ndata['time'] = torch.tensor(times).float()  # days\n",
        "                g.ndata['mag'] = torch.tensor(mags).float()\n",
        "                g.ndata['magerr'] = torch.tensor(magerrs).float()\n",
        "                #g.add_edges([i for i in range(n)], [(i+1)%n for i in range(n)])\n",
        "                #g.add_edges([i for i in range(n)], [(i-1)%n for i in range(n)])\n",
        "                \n",
        "                self.graphs.append(g)\n",
        "                self.isMicrolensed.append(microlensed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.graphs[idx], self.isMicrolensed[idx]\n",
        "\n",
        "\n",
        "train_ds = CustomDataset(training_path)\n",
        "validation_ds = CustomDataset(validation_path)\n",
        "\n",
        "nx.draw(dgl.to_networkx(train_ds[20][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08c31a535a8e41d08e4de0258465a7fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3baaca75c8ac4027a65cb63eb154c214",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnD7mWfjn3nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(samples):\n",
        "    # The input `samples` is a list, a batch of whatever comes out of your dataset object\n",
        "    graphs = [x[0] for x in samples]\n",
        "    labels = [x[1] for x in samples]\n",
        "    \n",
        "    batched_graph = dgl.batch(graphs, node_attrs=['time', 'mag', 'magerr'])\n",
        "    targets = torch.cat(labels)\n",
        "    \n",
        "    return batched_graph, targets.unsqueeze(1).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGDTIcKIuGW2",
        "colab_type": "text"
      },
      "source": [
        "## The Newtwork"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs14d7QUn3nL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "04e6ca53-2b0e-4c26-82a3-93c2e9530205"
      },
      "source": [
        "n_ft = 3  # number of node features (time, mag, magerr)\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "class EdgeNetwork(nn.Module):\n",
        "    def __init__(self, node_hidrep, edge_hidrep):\n",
        "        super(EdgeNetwork, self).__init__()\n",
        "        n_in = 2*node_hidrep\n",
        "        \n",
        "        # network:\n",
        "        sizes = [n_in] + [] + [edge_hidrep]\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(sizes)-1):\n",
        "            layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.ReLu()])\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        input = torch.cat((x.dst['node_hidrep'], x.src['node_hidrep']), dim=1)\n",
        "        output = self.network(input)\n",
        "        return {'edge_hidrep': output }\n",
        "\n",
        "\n",
        "\n",
        "class NodeNetwork(nn.Module):\n",
        "    def __init__(self, node_hidrep):\n",
        "        super(NodeNetwork, self).__init__()\n",
        "        n_in = node_hidrep\n",
        "\n",
        "        # network:\n",
        "        sizes = [n_in] + [] + [node_hidrep]\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(sizes)-1):\n",
        "            layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.ReLU() ])\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #mb = torch.mean( x.mailbox['edge_hidrep'] , dim=1 )\n",
        "        #input = torch.cat((mb, x.data['node_hidrep']), dim=1)\n",
        "        \n",
        "\n",
        "\n",
        "        out = self.network(x)\n",
        "        return {'node_hidrep': out }\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        # networks:\n",
        "        node_hidrep = 10\n",
        "        sizes_nodeinit = [n_ft] + [] + [node_hidrep]\n",
        "        self.update_loop_length = 20\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(sizes_nodeinit)-1):\n",
        "            layers.extend([nn.Linear(sizes_nodeinit[i], sizes_nodeinit[i+1]), nn.ReLU()])\n",
        "        self.node_init = nn.Sequential(*layers)\n",
        "        #self.edge_network = EdgeNetwork(node_hidrep, edge_hidrep)\n",
        "        self.node_network = NodeNetwork(node_hidrep)\n",
        "        \n",
        "    def forward(self, g):\n",
        "        features = torch.tensor(list(zip(g.ndata['time'], g.ndata['mag'], g.ndata['magerr'])))\n",
        "        g.ndata['node_hidrep'] = self.node_init(features)\n",
        "\n",
        "        for i in range(self.update_loop_length):\n",
        "            g.update_all(self.node_network)\n",
        "        \n",
        "        # eventually take max of all entries in all nodes (?), maybe you can apply functions with dgl.function ?\n",
        "        output = dgl.max_nodes(g, 'node_hidrep')\n",
        "        output = torch.max(output, 1, keepdim=True)[0]\n",
        "\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nclass EdgeNetwork(nn.Module):\\n    def __init__(self, node_hidrep, edge_hidrep):\\n        super(EdgeNetwork, self).__init__()\\n        n_in = 2*node_hidrep\\n        \\n        # network:\\n        sizes = [n_in] + [] + [edge_hidrep]\\n\\n        layers = []\\n        for i in range(len(sizes)-1):\\n            layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.ReLu()])\\n        self.network = nn.Sequential(*layers)\\n    \\n    def forward(self, x):\\n        input = torch.cat((x.dst['node_hidrep'], x.src['node_hidrep']), dim=1)\\n        output = self.network(input)\\n        return {'edge_hidrep': output }\\n\\n\\n\\nclass NodeNetwork(nn.Module):\\n    def __init__(self, node_hidrep):\\n        super(NodeNetwork, self).__init__()\\n        n_in = node_hidrep\\n\\n        # network:\\n        sizes = [n_in] + [] + [node_hidrep]\\n\\n        layers = []\\n        for i in range(len(sizes)-1):\\n            layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.ReLU() ])\\n        self.network = nn.Sequential(*layers)\\n    \\n    def forward(self, x):\\n        #mb = torch.mean( x.mailbox['edge_hidrep'] , dim=1 )\\n        #input = torch.cat((mb, x.data['node_hidrep']), dim=1)\\n        \\n\\n\\n        out = self.network(x)\\n        return {'node_hidrep': out }\\n\\n\\nclass Classifier(nn.Module):\\n    def __init__(self):\\n        super(Classifier, self).__init__()\\n\\n        # networks:\\n        node_hidrep = 10\\n        sizes_nodeinit = [n_ft] + [] + [node_hidrep]\\n        self.update_loop_length = 20\\n\\n        layers = []\\n        for i in range(len(sizes_nodeinit)-1):\\n            layers.extend([nn.Linear(sizes_nodeinit[i], sizes_nodeinit[i+1]), nn.ReLU()])\\n        self.node_init = nn.Sequential(*layers)\\n        #self.edge_network = EdgeNetwork(node_hidrep, edge_hidrep)\\n        self.node_network = NodeNetwork(node_hidrep)\\n        \\n    def forward(self, g):\\n        features = torch.tensor(list(zip(g.ndata['time'], g.ndata['mag'], g.ndata['magerr'])))\\n        g.ndata['node_hidrep'] = self.node_init(features)\\n\\n        for i in range(self.update_loop_length):\\n            g.update_all(self.node_network)\\n        \\n        # eventually take max of all entries in all nodes (?), maybe you can apply functions with dgl.function ?\\n        output = dgl.max_nodes(g, 'node_hidrep')\\n        output = torch.max(output, 1, keepdim=True)[0]\\n\\n\\n        return output\\n\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soJyGlbvMErI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepSet(nn.Module):\n",
        "\n",
        "    def _init_(self, config):\n",
        "\n",
        "        super(DeepSet, self)._init_()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TODvj6AMLJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arEZzPc-VKI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class NodeNetwork(nn.Module):\n",
        "    def __init__(self, node_hidrep):\n",
        "        super(NodeNetwork, self).__init__()\n",
        "        n_in =  node_hidrep\n",
        "\n",
        "        # network:\n",
        "        sizes = [n_in] + [10,10] + [node_hidrep]\n",
        "        \n",
        "        #sizes = [n_in] + [] + [node_hidrep]\n",
        "\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(sizes)-1):\n",
        "            layers.extend([nn.Linear(sizes[i], sizes[i+1]), nn.ReLU()])\n",
        "        self.network = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        #mb = torch.mean( x.mailbox['edge_hidrep'] , dim=1 )\n",
        "        \n",
        "        #input = torch.cat((x.data['node_hidrep']), dim=1)\n",
        "        \n",
        "        input = x.data['node_hidrep']\n",
        "\n",
        "\n",
        "        out = self.network(x)\n",
        "        return {'node_hidrep': out }\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        # networks:\n",
        "        node_hidrep = 20\n",
        "        sizes_nodeinit = [n_ft] + [] + [node_hidrep]\n",
        "        self.update_loop_length = 50\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(sizes_nodeinit)-1):\n",
        "            layers.extend([nn.Linear(sizes_nodeinit[i], sizes_nodeinit[i+1]), nn.ReLU()])\n",
        "\n",
        "        self.node_init = nn.Sequential(*layers)\n",
        "        #self.edge_network = EdgeNetwork(node_hidrep, edge_hidrep)\n",
        "        self.node_network = NodeNetwork(node_hidrep)\n",
        "        \n",
        "    def forward(self, g):  # OFEK exp(magnitude)\n",
        "        features = torch.tensor(list(zip(g.ndata['time'], torch.exp(g.ndata['mag']/(-2.5)), g.ndata['magerr'])))\n",
        "        g.ndata['node_hidrep'] = self.node_init(features)\n",
        "\n",
        "    #Make sure to give node neetwork and not edge\n",
        "\n",
        "        for i in range(self.update_loop_length):\n",
        "            \n",
        "\n",
        "            g.update_all(None, self.node_network)\n",
        "        \n",
        "        # OFEK changed max to mean\n",
        "        output = dgl.mean_nodes(g, 'node_hidrep')  # maybe you can apply functions with dgl.function ?\n",
        "        output = torch.mean(output, 1, keepdim=True)  # torch.max(output, 1, keepdim=True)[0]\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfX86zSVMDiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddlu-kVsuqGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "858cc9f2-3c87-4e47-fc8f-bcfa725894fb"
      },
      "source": [
        "net = Classifier()\n",
        "net.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (node_init): Sequential(\n",
              "    (0): Linear(in_features=3, out_features=20, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (node_network): NodeNetwork(\n",
              "    (network): Sequential(\n",
              "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=10, out_features=10, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=10, out_features=20, bias=True)\n",
              "      (5): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x-ALDRlwBDo",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgrXh0Jdn3nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(net, validation_ds):\n",
        "    test_data_loader = DataLoader(validation_ds, batch_size=20, shuffle=True, collate_fn=collate)\n",
        "\n",
        "    net.cpu()\n",
        "    net.eval()\n",
        "\n",
        "    true_positive = 0\n",
        "    false_positive = 0\n",
        "    true_negative = 0\n",
        "    false_negative = 0\n",
        "    total_positives = 0\n",
        "    total_negatives = 0\n",
        "\n",
        "    for i, (x,y) in enumerate(test_data_loader):\n",
        "            y = y.data.numpy()\n",
        "            prediction = net(x).cpu().data.numpy()\n",
        "            \n",
        "            prediction[prediction >= 0.5] = 1\n",
        "            prediction[prediction < 0.5] = 0\n",
        "            \n",
        "            total_positives+=len(np.where( y==1 )[0])\n",
        "            total_negatives+=len(np.where( y==0 )[0])\n",
        "            \n",
        "            true_positive+= len(np.where( (prediction==y) & (y==1) )[0])\n",
        "            # true_negative+= len(np.where( (prediction==y) & (y==0) )[0])\n",
        "            false_positive+= len(np.where( (prediction!=y) & (y==0) )[0])\n",
        "            # false_negative+= len(np.where( (prediction!=y) & (y==1) )[0])\n",
        "                    \n",
        "    print('Probability of detection:', true_positive/total_positives)  # probability of recognizing a microlensing when you see it\n",
        "    print('Probability of false alarm:', false_positive/total_negatives)  # probability for misclassification of a variable star as microlensing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBHUZcTcXPO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "a1889ba1fdf9475797d0376e88ee2cbd",
            "65ee33fc01504673b3ed56550180fb42",
            "9376ee0ceac6464f8da1c2a33f8450de",
            "15d8f389980f408898559480e78b19c0",
            "67f876a4f5b94b5abcebb0d801650ca0",
            "85b02d8e2eec4989afc85c457e64b6da",
            "a36ee0d1a5d84363b2fcedd2a88d02f8",
            "268086fc962b41c6805ada2c20dc3efa"
          ]
        },
        "outputId": "fc93f19a-bbee-43bb-d2a7-24717c74acb2"
      },
      "source": [
        "# options:\n",
        "# loss_func = nn.BCEWithLogitsLoss()\n",
        "# loss_func = nn.L1Loss()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adadelta(net.parameters(), lr=0.1)\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "losses = []\n",
        "\n",
        "data_loader = DataLoader(train_ds, batch_size=30, shuffle=True, collate_fn=collate)\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    net.train()\n",
        "    this_losses = []\n",
        "    for x,y in data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(x)\n",
        "        output = torch.cat((1-output, output), dim=1)\n",
        "        loss = loss_func(output.squeeze(), y.long().squeeze())\n",
        "        this_losses.append(float(loss))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    losses.append(np.mean(this_losses))\n",
        "    print('Epoch:', epoch, 'Loss:', round(losses[-1], 4))  # for some real-time indication (couldn't manage to get this to dynamically plot)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1889ba1fdf9475797d0376e88ee2cbd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-13e2cab5a4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-2e09b47e01f4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# OFEK changed max to mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapply_node_func\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m             \u001b[0mapply_node_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_node_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3230\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mmessage_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3231\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU3-bAMS-D-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "38d39aa6-dc54-455d-da4a-9babc0fa2a9f"
      },
      "source": [
        "# plot the printed losses:\n",
        "losses = np.array(losses)\n",
        "plt.plot(losses[1:],label='training loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "evaluate(net, validation_ds)  # show P_D, P_FA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9806383cbbdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# show P_D, P_FA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-5fb308109036>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(net, validation_ds)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-216d9966c01e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_loop_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# OFEK changed max to mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dgl/graph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func)\u001b[0m\n\u001b[1;32m   3229\u001b[0m             \u001b[0mapply_node_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_node_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmessage_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3231\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3233\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VfHxWg7aL98",
        "colab_type": "text"
      },
      "source": [
        "## Save\n",
        "Don't forget to download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cVQVmottKTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timestamp = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "torch.save(net.state_dict(), 'model_' + timestamp + '.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eomLQW_E0eaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}